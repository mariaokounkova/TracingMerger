{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## imports\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import h5py\n",
    "import os\n",
    "from math import pi, sqrt\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "rc('text', usetex=True)\n",
    "import seaborn as sns\n",
    "from os import path\n",
    "from scipy import integrate\n",
    "\n",
    "# Plot parameters\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['axes.labelsize'] = 24\n",
    "matplotlib.rcParams['xtick.labelsize'] = 30\n",
    "matplotlib.rcParams['ytick.labelsize'] = 30\n",
    "matplotlib.rcParams['xtick.major.size'] = 20\n",
    "matplotlib.rcParams['ytick.major.size'] = 20\n",
    "matplotlib.rcParams['xtick.top'] = True\n",
    "matplotlib.rcParams['xtick.direction'] = 'in'\n",
    "matplotlib.rcParams['xtick.minor.visible'] = True\n",
    "matplotlib.rcParams['xtick.minor.size'] = 10\n",
    "matplotlib.rcParams['ytick.minor.size'] = 10\n",
    "matplotlib.rcParams['legend.fontsize'] = 18\n",
    "matplotlib.rcParams['legend.frameon'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Data helper functions\n",
    "\n",
    "def CutTimes(time, data, TLow, TUp): \n",
    "    TLowIndex = np.where(time <= TLow)[0][0]\n",
    "    TUpIndex = np.where(time >= TUp)[0][-1]\n",
    "    time = time[TLowIndex:TUpIndex]\n",
    "    data = data[TLowIndex:TUpIndex]\n",
    "    return time, data\n",
    "\n",
    "def CutTimesArray(time, Arr, TLow, TUp): \n",
    "    TLowIndex = np.where(time <= TLow)[0] \n",
    "    if(len(TLowIndex) > 0):\n",
    "        TLowIndex = TLowIndex[-1]\n",
    "    else:\n",
    "        TLowIndex = 0\n",
    "    TUpIndex = np.where(time >= TUp)[0]\n",
    "    if(len(TUpIndex) > 0):\n",
    "        TUpIndex = TUpIndex[0]\n",
    "    else:\n",
    "        TUpIndex = -1\n",
    "        \n",
    "    time = time[TLowIndex:TUpIndex]\n",
    "    Ans = []\n",
    "    for data in Arr:\n",
    "        Ans.append(data[TLowIndex:TUpIndex])\n",
    "    return time, Ans \n",
    "\n",
    "\n",
    "def GetPeakTimeMode(time, data): ###\n",
    "    ## Peak time being the peak of the magnitude of the data\n",
    "    t_peak = time[np.argmax(np.absolute(data))]\n",
    "    return t_peak\n",
    "\n",
    "def GetPeakTimeModeReal(time, data): ###\n",
    "    ## Peak time being the peak of the magnitude of the data\n",
    "    t_peak = time[np.argmax(np.real(data))]\n",
    "    return t_peak\n",
    "\n",
    "def SubtractPeakTimeMode(time, data): ###\n",
    "    t_peak = GetPeakTimeMode(time, data)\n",
    "    return time - t_peak\n",
    "\n",
    "def SubtractPeakTimeModeReal(time, data): ###\n",
    "    t_peak = GetPeakTimeModeReal(time, data)\n",
    "    return time - t_peak\n",
    "\n",
    "def InterpolateTimes(time, data, time_dest):\n",
    "    \"\"\" Interpolates time, data onto new time axis\n",
    "        time_dest \"\"\"\n",
    "    interpolant = scipy.interpolate.CubicSpline(time, data)\n",
    "    return interpolant(time_dest)\n",
    "\n",
    "def GetCameraPosition(p):\n",
    "    p = p.split('Trace')[1]\n",
    "    x = p.split('_')[1]\n",
    "    y = p.split('_')[2]\n",
    "    z = p.split('_')[3]\n",
    "    return '[' + x + ',' + y + ',' + z + ']'\n",
    "\n",
    "def GetTime(p):\n",
    "    p = p.split('Trace')[1]\n",
    "    t = p.split('_')[4]\n",
    "    t = t.split('/')[0]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in horizon data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Read in horizon trajectories\n",
    "\n",
    "Lev = \"2\"\n",
    "\n",
    "def read_horizon_trajectories(Horizon):\n",
    "    \"\"\" Horizon is a string corresponding to the BH we're interested in [A, B, C]\"\"\"\n",
    "    f = \"Data/HeadOn_Harmonic/JoinedLev\" + Lev + \"/ApparentHorizons/Trajectory_Ah\" + Horizon + \".dat\"\n",
    "    t, x, y, z = np.loadtxt(f, comments=\"#\",usecols=([0,1,2,3]),unpack=True)\n",
    "    return t, x, y, z\n",
    "\n",
    "## Build the horizon interpolants\n",
    "t_a, x_a, y_a, z_a = read_horizon_trajectories(\"A\")\n",
    "spl_x_a = InterpolatedUnivariateSpline(t_a, x_a)\n",
    "spl_y_a = InterpolatedUnivariateSpline(t_a, y_a)\n",
    "spl_z_a = InterpolatedUnivariateSpline(t_a, z_a)\n",
    "\n",
    "t_b, x_b, y_b, z_b = read_horizon_trajectories(\"B\")\n",
    "spl_x_b = InterpolatedUnivariateSpline(t_b, x_b)\n",
    "spl_y_b = InterpolatedUnivariateSpline(t_b, y_b)\n",
    "spl_z_b = InterpolatedUnivariateSpline(t_b, z_b)\n",
    "\n",
    "t_c, x_c, y_c, z_c = read_horizon_trajectories(\"C\")\n",
    "t_merger = t_b[-1]\n",
    "t_ringdown = t_c[0]\n",
    "spl_x_c = InterpolatedUnivariateSpline(t_c, x_c)\n",
    "spl_y_c = InterpolatedUnivariateSpline(t_c, y_c)\n",
    "spl_z_c = InterpolatedUnivariateSpline(t_c, z_c)\n",
    "\n",
    "def horizon_at_time(time, Horizon):\n",
    "    if Horizon == \"A\":\n",
    "        return spl_x_a(time), spl_y_a(time), spl_z_a(time)\n",
    "    if Horizon == \"B\":\n",
    "        return spl_x_b(time), spl_y_b(time), spl_z_b(time)\n",
    "    if Horizon == \"C\":\n",
    "        return spl_x_c(time), spl_y_c(time), spl_z_c(time)\n",
    "    else:\n",
    "        print(\"Unrecognized horizon argument\")\n",
    "\n",
    "def distance_sqr(xx, yy, zz, xx_h, yy_h, zz_h):\n",
    "    return (xx - xx_h)**2 + (yy - yy_h)**2 + (zz - zz_h)**2\n",
    "    \n",
    "def distance_to_horizon(time, xx, yy, zz):\n",
    "    \"\"\" time, x,x yy, zz are scalars for the position\"\"\"\n",
    "    if time <= t_merger:\n",
    "        min_dist = 1e10\n",
    "        for horizon in [\"A\", \"B\"]:\n",
    "            \"\"\" Have to minimize over AhA and AhB distances\"\"\"\n",
    "            xx_h, yy_h, zz_h = horizon_at_time(time, horizon)\n",
    "            dist = distance_sqr(xx, yy, zz, xx_h, xx_h, xx_h)\n",
    "            min_dist = min(min_dist, dist)\n",
    "        return sqrt(min_dist)\n",
    "    elif time > t_merger:\n",
    "        xx_h, yy_h, zz_h = horizon_at_time(time, \"C\")\n",
    "        dist = distance_sqr(xx, yy, zz, xx_h, xx_h, xx_h)\n",
    "        return sqrt(dist)\n",
    "    else:\n",
    "        print(\"somehow here\")\n",
    "        print(time, t_merger, t_ringdown)\n",
    "                \n",
    "def min_distance_to_horizon(t, x, y, z):\n",
    "    \"\"\" Returns the minimum distance of a geodesic to a horizon over all time\n",
    "        t, x, y, z are arrays with the history of the geodesic\"\"\"\n",
    "    min_distance = 1e10\n",
    "                \n",
    "    ## minimize over the times\n",
    "    for time, xx, yy, zz in zip(t, x, y, z):\n",
    "        dist_horizon = distance_to_horizon(time, xx, yy, zz)\n",
    "        min_distance = min(min_distance, dist_horizon)\n",
    "\n",
    "    return(sqrt(min_distance))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in lensing camera data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Lensing camera data\n",
    "def GetCameraData(p):\n",
    "    \n",
    "    file = p + 'RefinementMethodData.h5'\n",
    "    f = h5py.File(file, 'r')\n",
    "    data = f['LensingCore.dat']\n",
    "    \n",
    "    tags = data[:,0]\n",
    "    tags = tags.astype(int)\n",
    "    x_pos = data[:,1]\n",
    "    y_pos = data[:,2]\n",
    "    surface = data[:,4]\n",
    "    \n",
    "    return tags, x_pos, y_pos, surface\n",
    "\n",
    "def GrabSurfaceIndices(surface, fate):\n",
    "    \n",
    "    i = np.where(surface == fate)[0]\n",
    "    return i\n",
    "\n",
    "def SelectCameraGeodesics(p, fate):\n",
    "    \n",
    "    tags, x_pos, y_pos, surface = GetCameraData(p)\n",
    "    \n",
    "    i = np.where(surface == fate)[0]\n",
    "    \n",
    "    return tags[i], x_pos[i], y_pos[i], surface[i]\n",
    "    \n",
    "def GetInfinityGeodesics(p):\n",
    "    \"\"\" \n",
    "    inf = np.where(surface == 1.)[0]\n",
    "    infty = np.where(surface == 7.)[0]\n",
    "    aha = np.where(surface == 2.)[0]\n",
    "    ahb = np.where(surface == 3.)[0]\n",
    "    ahc = np.where(surface == 4.)[0]\n",
    "    \"\"\"\n",
    "    file = p + 'RefinementMethodData.h5'\n",
    "    f = h5py.File(file, 'r')\n",
    "    data = f['LensingCore.dat']\n",
    "    surface = data[:,4]\n",
    "    #return GrabSurfaceIndices(surface, 1)\n",
    "    return GrabSurfaceIndices(surface, 7)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in geodesics trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Read geodesic trajectories from Node0.h5 and dump to .dat files\n",
    "\n",
    "def ReadGeodesicData(p, t_start, t_end):\n",
    "    \"\"\" Read in an array of times and positions for all geodesics at once, \n",
    "        and return the trajectories indexed by geodesic \"\"\"\n",
    "        \n",
    "    def AppendGeodesicsTime(Lev, Run):\n",
    "\n",
    "        print(\"Reading Geodesic data for \" + Lev + \" and \" + Run)\n",
    "\n",
    "        file = p + '/' + Lev + '/' + Run + '/Run/Node0.h5'\n",
    "        f = h5py.File(file, 'r')\n",
    "        ## grab the .dat files\n",
    "        keys = [k for k in f.keys() if 'dat' in k]\n",
    "        ## Array of times from the .dat files\n",
    "        times = [float(k.split('.dat')[0]) for k in keys]\n",
    "        ## sort keys according to times\n",
    "        times, keys = zip(*sorted(zip(times, keys)))\n",
    "        # grab the number of geodesics\n",
    "        N_geodesics = len(f[keys[-1]][:,0])\n",
    "        print(\"Total geodesics: \", N_geodesics, \"Time steps: \", len(times))\n",
    "        ## Minimum index\n",
    "        m = int(f[keys[-1]][:,0][0])\n",
    "        print(\"Geodesic index offset of this refinement iteration: \", m)\n",
    "    \n",
    "        X = [ [] for _ in range(N_geodesics)]\n",
    "        Y = [ [] for _ in range(N_geodesics)]\n",
    "        Z = [ [] for _ in range(N_geodesics)]\n",
    "        L = [ [] for _ in range(N_geodesics)]\n",
    "        T = [ [] for _ in range(N_geodesics)]\n",
    "    \n",
    "        for k, t in zip(keys, times):\n",
    "            print(t)\n",
    "            if ((t > t_start) and (t < t_end)):\n",
    "                print(\"%.1f  \" % t, end = '')\n",
    "                data = f[k]\n",
    "                ## indices and positions for all geodesics at this time\n",
    "                indices = data[:,0]\n",
    "                if (len(data[0]) == 7):\n",
    "                    \"\"\" If we've run the numerical evolution so that we haven't \n",
    "                        evolved lapse p0 -- just set lapsep0 to 1 in the files. \n",
    "                        This field need to be in the resulting .dat file for the \n",
    "                        paraview trajectory visualization\"\"\"\n",
    "                    x = data[:,4]\n",
    "                    y = data[:,5]\n",
    "                    z = data[:,6]\n",
    "                    l = np.ones(len(x))\n",
    "                elif (len(data[0]) == 8):\n",
    "                    \"\"\" If we have evolved lapse p0\"\"\"\n",
    "                    l = data[:,1]\n",
    "                    x = data[:,5]\n",
    "                    y = data[:,6]\n",
    "                    z = data[:,7]\n",
    "                else:\n",
    "                    print(\"Unrecognized number of variables\")\n",
    "                ## fill in the array for each index\n",
    "                for i, j in zip(indices.astype(int), range(len(indices))):\n",
    "                    X[i-m] = np.append(X[i-m], x[j])\n",
    "                    Y[i-m] = np.append(Y[i-m], y[j])\n",
    "                    Z[i-m] = np.append(Z[i-m], z[j])\n",
    "                    L[i-m] = np.append(L[i-m], l[j])\n",
    "                    T[i-m] = np.append(T[i-m], t)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        ## Once we have the arrays constructed, append them to the file\n",
    "        print('Read the geodesic data, now writing the files')\n",
    "        print(\"Masha\", len(T))\n",
    "        for a in range(len(T)):\n",
    "            ##if (len(T[a]) > 1):\n",
    "                ## Remember to add in the minimum index since the starting \n",
    "                ## geodesic index just gets incremented during reach refinement\n",
    "                ## level (by the number of geodesics that came from the levels before)\n",
    "            ff = open(p + '/Trajectories/' + str(a + m) + '.dat','ab')\n",
    "            np.savetxt(ff, np.c_[T[a],X[a],Y[a],Z[a],L[a]])\n",
    "            ff.close()\n",
    "        print('Finished writing the files')\n",
    "            \n",
    "    ## Go through the refinement levels and the segments\n",
    "    RefinementLevs = [el for el in os.listdir(p) if \"Lev\" in el]\n",
    "    print(\"RefinementLevs:\", RefinementLevs)\n",
    "    for lev in RefinementLevs:\n",
    "        Segments = os.listdir(p + '/' + lev)\n",
    "        print(lev + \" Segments:\", Segments)\n",
    "        for segment in Segments:\n",
    "            AppendGeodesicsTime(lev, segment)\n",
    "\n",
    "def MakeGeodesicDatFiles(p, t_start, t_end):\n",
    "    \"\"\" Print the result of ReadGeodesicData to files \"\"\"\n",
    "    ReadGeodesicData(p, t_start, t_end)\n",
    "\n",
    "## Functions for reading GetTrajectoriesFromH5 output\n",
    "def GetGeodesicTrajectory(p, n, Culled = False):\n",
    "    \"\"\" Read in the post-processed trajectory for the nth geodesic \"\"\"\n",
    "    f = p + 'Trajectories/' + str(n) + '.dat'\n",
    "    if Culled:\n",
    "        f = p + 'CulledTrajectories/' + str(n) + '.dat'\n",
    "    #t, x, y, z, lapse = np.loadtxt(f, comments=\"#\",usecols=([0,5,6,7,1]),unpack=True)\n",
    "    t, x, y, z, lapse = np.loadtxt(f, comments=\"#\",usecols=([0,1,2,3,4]),unpack=True)\n",
    "    return t, x, y, z, lapse\n",
    "\n",
    "def GetGeodesicIndices(p, Culled = False):\n",
    "    \"\"\" Return the indices of all of the geodesics we have printed to file \"\"\"\n",
    "    Files = os.listdir(p + '/Trajectories')\n",
    "    if Culled:\n",
    "        Files = os.listdir(p + '/CulledTrajectories')\n",
    "    Indices = [int(file.split('.dat')[0]) for file in Files]\n",
    "    Indices = sorted(Indices)\n",
    "    return Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##MakeGeodesicDatFiles('Data/TraceHeadOn_0_0_100_500_BohnNumerical', 330, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero crossings computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Zero crossings computations\n",
    "def ComputeZeroCrossings(p, n):\n",
    "    \"\"\" Compute the number of zero crossings in the y-z plane - \n",
    "        useful for head-on runs where the collision happens\n",
    "        along the x axis \"\"\"\n",
    "    t, x, y, z, lapse = GetGeodesicTrajectory(p, n)\n",
    "    theta = np.arctan2(z, y)\n",
    "    zero_crossings = len(np.where(np.diff(np.sign(theta)))[0])\n",
    "    return zero_crossings\n",
    "\n",
    "def MakeZeroCrossingsFile(p):\n",
    "    \"\"\" Make a file with the format [geodesic index, number of zero crossings] so \n",
    "        that we only have to compute the number of zero crossings once \"\"\"\n",
    "    ns = GetGeodesicIndices(p)\n",
    "    crossings = [ComputeZeroCrossings(p, n) for n in ns]\n",
    "    np.savetxt(p + 'ZeroCrossings.dat', np.c_[ns, crossings], fmt = '%d %d')\n",
    "    \n",
    "def GetGeodesicsZeroCrossings(p):\n",
    "    \"\"\" Return the zero crossings for each index \"\"\"\n",
    "    f = p + 'ZeroCrossings.dat'\n",
    "    ns, zero_crossings = np.loadtxt(f, comments=\"#\",usecols=([0,1]),unpack=True,dtype=int)\n",
    "    return ns, zero_crossings\n",
    "\n",
    "def GetGeodesicsZeroCrossingsIndices(p, N):\n",
    "    \"\"\" Return the indices of the geodesics that make N zero-crossings \"\"\"\n",
    "    f = p + 'ZeroCrossings.dat'\n",
    "    ns, zero_crossings = np.loadtxt(f, comments=\"#\",usecols=([0,1]),unpack=True,dtype=int)\n",
    "    indices = ns[np.where(zero_crossings == N)[0]]\n",
    "    return indices\n",
    "\n",
    "def GetGeodesicsMaxZeroCrossings(p):\n",
    "    \"\"\" Return the maximum number N of zero crossings for a given run, \n",
    "        along with the indices of the geodesics that make N zero-crossings \"\"\"\n",
    "    f = p + 'ZeroCrossings.dat'\n",
    "    ns, zero_crossings = np.loadtxt(f, comments=\"#\",usecols=([0,1]),unpack=True,dtype=int)\n",
    "    max_N = max(zero_crossings)\n",
    "    indices = ns[np.where(zero_crossings == max_N)[0]]\n",
    "    return max_N, indices\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##MakeZeroCrossingsFile('Data/TraceHeadOn_0_0_100_319.7_quick/')\n",
    "#GetGeodesicsZeroCrossingsIndices('Data/TraceHeadOn_0_0_100_319.7/', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot geodesic trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Plot geodesic trajectories\n",
    "def PlotGetTrajectoriesFromH5(p):\n",
    "\n",
    "    max_N, Indices = GetGeodesicsMaxZeroCrossings(p)\n",
    "    print(max_N, len(Indices))\n",
    "    \n",
    "    #Indices = [75256]\n",
    "    \n",
    "    cs = sns.color_palette('Paired', n_colors=len(Indices))\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for n, color in zip(Indices, cs):\n",
    "        t, x, y, z, lapse = GetGeodesicTrajectory(p, n)\n",
    "        #t, Arr = CutTimesArray(t, [x, y, z, lapse], 140, 180)\n",
    "        #x, y, z, lapse = Arr\n",
    "        ax.plot(x, y, z, lw = 2.0, label = n, color = color)\n",
    "        #ss = ax.scatter(x, y, z, s=20, c=lapse, cmap = 'rainbow', vmin=0, vmax=12)\n",
    "        #skip = 10\n",
    "        #for tt, xx, yy, zz in zip(t[::skip], x[::skip], y[::skip], z[::skip]):\n",
    "        #    ax.text(xx, yy, zz, str(tt))\n",
    "    #cbar = fig.colorbar(ss, fraction=0.03, pad=0.04,  orientation=\"horizontal\")\n",
    "    #cbar.set_label(r'$\\log \\alpha p_0$', rotation=0)\n",
    "                \n",
    "    \n",
    "    \n",
    "    #Add in the horizons\n",
    "    for horizon, color in zip([\"A\", \"B\", \"C\"], [\"blue\", \"lightblue\", \"yellow\"]):\n",
    "        t_h, x_h, y_h, z_h = read_horizon_trajectories(horizon)\n",
    "        #t_h, x_h, y_h, z_h, temp = CutTimesGeodesic(t_h, x_h, y_h, z_h, z_h, 155, 180)\n",
    "        plt.plot(x_h, y_h, z_h, color='black', lw = 2.0, ls='-')\n",
    "    #ax.scatter([0.0], [0.0], [0.0], s = 20, color='black')  \n",
    "    \n",
    "    ax.set_xlabel('x/M',labelpad=20)\n",
    "    ax.set_ylabel('y/M', labelpad=20)\n",
    "    ax.set_zlabel('z/M', labelpad=20)\n",
    "    \n",
    "    lim = 10.0\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "    ax.set_zlim(-lim, lim)\n",
    "    \n",
    "    ax.set_title('Camera = ' + GetCameraPosition(p) + ' M' + ', $t_\\mathrm{start}$ = ' + \\\n",
    "                 GetTime(p) + ' M', fontsize=20, loc='left')\n",
    "    \n",
    "    ax.grid(False)\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis._axinfo['tick']['inward_factor'] = 0\n",
    "    ax.xaxis._axinfo['tick']['outward_factor'] = 0.4\n",
    "    ax.yaxis._axinfo['tick']['inward_factor'] = 0\n",
    "    ax.yaxis._axinfo['tick']['outward_factor'] = 0.4\n",
    "    ax.zaxis._axinfo['tick']['inward_factor'] = 0\n",
    "    ax.zaxis._axinfo['tick']['outward_factor'] = 0.4\n",
    "    ax.zaxis._axinfo['tick']['outward_factor'] = 0.4\n",
    "    #ax.set_axis_off()\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n"
     ]
    }
   ],
   "source": [
    "PlotGetTrajectoriesFromH5('Data/TraceHeadOn_0_0_100_269.7/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot lensing refinement method results + final positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Plot X, Y camera data and kappas on top of it\n",
    "\n",
    "def PlotRefinementMethodResult(p, shadow=False, zero_crossings=False):\n",
    "    \n",
    "    tags, x_pos, y_pos, surface = GetCameraData(p)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    \n",
    "    if shadow:\n",
    "        \n",
    "        s = 5.0\n",
    "    \n",
    "        inf = GrabSurfaceIndices(surface, 1)\n",
    "        aha = GrabSurfaceIndices(surface, 2)\n",
    "        ahb = GrabSurfaceIndices(surface, 3)\n",
    "        ahc = GrabSurfaceIndices(surface, 4)\n",
    "        infty = GrabSurfaceIndices(surface, 7)\n",
    "        \n",
    "        #plt.scatter(x_pos[infty], y_pos[infty], s=s, c='#aeebd8', label=r'Out to $\\infty$')\n",
    "        #plt.scatter(x_pos[inf], y_pos[inf], s=s, c='lightblue', label=r'Out to $\\infty$')\n",
    "        #plt.scatter(x_pos[aha], y_pos[aha], s=s, c='#00abd1', label=r'Close to AH A')\n",
    "        plt.scatter(x_pos[ahb], y_pos[ahb], s=s, c='#d10084', label=r'Close to AH B', picker = 1)\n",
    "        #plt.scatter(x_pos[ahc], y_pos[ahc], s=s, c='black', label=r'Close to Final AH')\n",
    "        \n",
    "        #tolerance = 1 # points\n",
    "        #ax.plot(range(10), 'o', picker=tolerance)\n",
    "        \n",
    "        def on_pick(event):\n",
    "            ind = event.ind\n",
    "            print(ind, x_pos[ahb][ind], y_pos[ahb][ind], tags[ahb][ind])\n",
    "            print()\n",
    "\n",
    "        fig.canvas.callbacks.connect('pick_event', on_pick)\n",
    "    \n",
    "    elif zero_crossings:\n",
    "        \n",
    "        s = 1.0\n",
    "        nums = [7, 6, 5, 4, 3, 2, 1, 0]\n",
    "        #nums = [4]\n",
    "        cs = ['orange', 'purple', '#00eeff', 'black', 'blue', 'red', 'yellow', 'black']\n",
    "        infty = GrabSurfaceIndices(surface, 7)\n",
    "        indices, zero = GetGeodesicsZeroCrossings(p)\n",
    "        print(max(zero))\n",
    "        for num, color in zip(nums, cs):\n",
    "            indx = GrabSurfaceIndices(zero, num)\n",
    "            ii = list(set(indx) & set(infty))\n",
    "            plt.scatter(x_pos[ii], y_pos[ii], s=s, label=str(num), color=color, picker = 1)\n",
    "\n",
    "            def on_pick(event):\n",
    "                ind = event.ind\n",
    "                print(ind, x_pos[ii][ind], y_pos[ii][ind], tags[ii][ind])\n",
    "                print()\n",
    "\n",
    "            if len(nums) == 1:\n",
    "                fig.canvas.callbacks.connect('pick_event', on_pick)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tags_fs, kappas = GetFrenetSerretMaxCurvatures(p)\n",
    "        kappas = np.log10(kappas)\n",
    "        \n",
    "        indices = GrabSurfaceIndices(surface, 7)\n",
    "        ss = plt.scatter(x_pos[indices], y_pos[indices], s=20, c=kappas[indices], \\\n",
    "                         cmap = 'jet', vmin=2, vmax = 3.75)\n",
    "        cbar = fig.colorbar(ss, fraction=0.03, pad=0.04)\n",
    "        cbar.set_label(r'Max $\\log_{10} \\kappa$', rotation=-90, labelpad=20)\n",
    "        \n",
    "        a = [x for _,x in sorted(zip(kappas[indices],tags[indices]))][::-1][0:4]\n",
    "        print(a)\n",
    "\n",
    "        #a = [32584, 11037, 24611, 6013]\n",
    "        #for xx, yy, tag in zip(x_pos[a], y_pos[a],tags[a]):\n",
    "        #    plt.text(xx, yy, str(tag), fontsize=8)\n",
    "        \n",
    "    plt.title('Camera = ' + GetCameraPosition(p) + ' M' + ', $t_\\mathrm{start}$ = ' + \\\n",
    "                 GetTime(p) + ' M', fontsize=20, loc='left')\n",
    "\n",
    "    plt.xlabel(r'Camera X')\n",
    "    plt.ylabel(r'Camera Y')\n",
    "    if shadow:\n",
    "        legend = plt.legend(title='Geodesic Fate', loc='upper left', fontsize=16, framealpha=1.0)\n",
    "        plt.setp(legend.get_title(),fontsize=20)\n",
    "        for han in legend.legendHandles:\n",
    "            han._sizes = [30]\n",
    "    if zero_crossings:\n",
    "        legend = plt.legend(title='Number of zero crossings', ncol = 3, \\\n",
    "                            loc='upper left', fontsize=16, framealpha=1.0)\n",
    "        plt.setp(legend.get_title(),fontsize=20)\n",
    "        for han in legend.legendHandles:\n",
    "            han._sizes = [30]\n",
    "            \n",
    "    lim = 0.25\n",
    "    plt.xlim(0.5 - lim, 0.5 + lim)\n",
    "    plt.ylim(0.5 - lim, 0.5 + lim)\n",
    "    plt.tight_layout()\n",
    "#     if shadow:\n",
    "#         plt.savefig('Shadow_' + GetTime(p) + '.pdf')\n",
    "#     if zero_crossings: \n",
    "#         plt.savefig('Zero_' + GetTime(p) + '.pdf')\n",
    "#     else: \n",
    "#         plt.savefig('ZoomCamera_' + GetTime(p) + '.pdf')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "pp_arr = [269.7]\n",
    "data_locs = ['Data/TraceHeadOn_0_0_100_' + str(pp) + '/' for pp in pp_arr]\n",
    "for p in data_locs:\n",
    "    #PlotRefinementMethodResult(p, shadow=True)\n",
    "    PlotRefinementMethodResult(p, zero_crossings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Interpolate a quantity (like the max Frenet-Serret curvature) onto the camera data\n",
    "def CameraInterpolation(p):\n",
    "\n",
    "    file = p + 'RefinementMethodData.h5'\n",
    "    f = h5py.File(file, 'r')\n",
    "    data = f['LensingCore.dat']\n",
    "    \n",
    "    tags = data[:,0]\n",
    "    print(len(tags))\n",
    "    tags = tags.astype(int)\n",
    "    x_pos = data[:,1]\n",
    "    y_pos = data[:,2]\n",
    "    surface = data[:,4]\n",
    "    \n",
    "    tags_fs, kappas = GetFrenetSerretMaxCurvatures(p)\n",
    "    print(min(kappas), max(kappas))\n",
    "    kappas = np.log10(kappas)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    \n",
    "    z = np.array(kappas)\n",
    "    rows = np.array(x_pos) \n",
    "    cols = np.array(y_pos) \n",
    "    \n",
    "    ## Number of points to interpolate to\n",
    "    YY = 1000\n",
    "    XX = 1000\n",
    "    ## number of contours\n",
    "    N_cont = 1000 \n",
    "    ## Bounds for the colobar\n",
    "    cmap = 'jet'\n",
    "    vmin = 3.0\n",
    "    vmax = 3.6\n",
    "    lim = 0.2\n",
    "    ## Bounds for the figure\n",
    "\n",
    "    \n",
    "    xi = np.linspace(0.5 - lim, 0.5 + lim, XX)\n",
    "    yi = np.linspace(0.5 - lim, 0.5 + lim, YY)\n",
    "\n",
    "    GD = scipy.interpolate.griddata((rows, cols), z.ravel(),\n",
    "                          (xi[None,:], yi[:,None]), method='cubic')\n",
    "\n",
    "    CS = plt.contourf(xi,yi,GD,N_cont,cmap = cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(GD)\n",
    "    m.set_clim(vmin, vmax)\n",
    "    cbar = plt.colorbar(m, boundaries=np.linspace(vmin, vmax, 6), fraction=0.03, pad=0.01,  orientation=\"vertical\")\n",
    "    cbar.set_label(r'Max $\\log_{10} \\kappa$', rotation=-90, labelpad=20)\n",
    "    \n",
    "    plt.xlabel(r'Camera X')\n",
    "    plt.ylabel(r'Camera Y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
